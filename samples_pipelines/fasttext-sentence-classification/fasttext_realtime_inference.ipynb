{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using a Trained FastText Model for Realtime Inference\n",
    "\n",
    "If your system requires low-latency processing (to process a single document or small set of documents quickly), then the realtime inference is the right choice. In this notebook, we will demonstrate how to make a prediction of an input sentence with a trained [fastText](https://fasttext.cc/) model.\n",
    "\n",
    "The outline of this notebook is as follows:\n",
    "\n",
    "- Visualize the pipeline associated with the pipeline run.\n",
    "- Get a step run with information from the visualization.\n",
    "- Get the port with the trained model from the step run.\n",
    "- Download the model from the port and register it to the workspace.\n",
    "- Deploy the model to local/ACI/AKS.\n",
    "\n",
    "## Prerequisites\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at https://github.com/Azure/MachineLearningNotebooks first. This sets you up with a working config file that has information on your workspace, subscription id, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Model, Workspace, Run\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import LocalWebservice, AciWebservice, AksWebservice\n",
    "from azureml.pipeline.wrapper import PipelineRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to workspace\n",
    "Create a workspace object from the existing workspace. Workspace.from_config() reads the file config.json and loads the details into an object named workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DesignerDRI_EASTUS\n",
      "DesignerDRI\n",
      "eastus\n",
      "74eccef0-4b8d-4f83-b5f9-fa100d155b22\n",
      "dict_keys(['attached-aks', 'default', 'compute', 'aml-compute', 'aml-compute-gpu'])\n"
     ]
    }
   ],
   "source": [
    "workspace = Workspace.from_config('config.json')\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id,\n",
    "      workspace.compute_targets.keys(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of experiment names from the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample10',\n",
       " 'sample5',\n",
       " 'sample5-realtime',\n",
       " 'simple10-batch',\n",
       " 'pythonscript',\n",
       " 'Data_dependency',\n",
       " 'clement',\n",
       " 'new_module',\n",
       " 'test_module2',\n",
       " 'test_m',\n",
       " 'module_SDK_local_module_test',\n",
       " 'fasttext_pipeline',\n",
       " 'fasttext_batch_inference',\n",
       " 'fasttext_pipeline2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name_list = [exp.name for exp in Experiment.list(workspace)]\n",
    "exp_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the experiment you want with its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>DesignerDRI_EASTUS</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: fasttext_pipeline,\n",
       "Workspace: DesignerDRI_EASTUS)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"fasttext_pipeline\"\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the latest and completed run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>38da18fb-5926-4fbd-8a1e-dd167bc2c995</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/38da18fb-5926-4fbd-8a1e-dd167bc2c995?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: fasttext_pipeline,\n",
       "Id: 38da18fb-5926-4fbd-8a1e-dd167bc2c995,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# azureml.pipeline.core.run.PipelineRun\n",
    "run = Run.list(experiment, status='Completed').__next__()\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a PipelineRun object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>38da18fb-5926-4fbd-8a1e-dd167bc2c995</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/38da18fb-5926-4fbd-8a1e-dd167bc2c995?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: fasttext_pipeline,\n",
       "Id: 38da18fb-5926-4fbd-8a1e-dd167bc2c995,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = run.id\n",
    "# azureml.pipeline.wrapper.PipelineRun\n",
    "pipeline_run = PipelineRun(experiment, run_id)\n",
    "pipeline_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "try {\n",
       "    require.undef(\"validate_widget\")\n",
       "\n",
       "    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "        var ValidateView = widgets.DOMWidgetView.extend({\n",
       "            render () {\n",
       "                window.widget_self = this\n",
       "                var visualize_id = this.model.get('visualize_id')\n",
       "\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[visualize_id]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[visualize_id] = \"widget\"\n",
       "                console.log(\"load as widget\", Date.now())\n",
       "\n",
       "                var lib_url = this.model.get('lib_url')\n",
       "                var graph_json = JSON.parse(this.model.get('graph_json'))\n",
       "                var env_json = JSON.parse(this.model.get('env_json'))\n",
       "                var container_id = this.model.get('container_id')\n",
       "\n",
       "                window.render_container_id = container_id\n",
       "                window.graph_json = graph_json\n",
       "                window.graph_json_to_compare = undefined\n",
       "                window.env_json = env_json\n",
       "                window.before_script = performance.now()\n",
       "\n",
       "                var container = document.createElement('div')\n",
       "                container.id = container_id\n",
       "                this.el.appendChild(container)\n",
       "\n",
       "                var style = document.createElement('style')\n",
       "                style.innerHTML = [\n",
       "                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n",
       "                    \".cell-output-ipywidget-background { background: transparent !important }\"\n",
       "                ].join('')\n",
       "                this.el.appendChild(style)\n",
       "\n",
       "                this.model.on('msg:custom', dispatchMessage, this);\n",
       "\n",
       "                if (!window.__event_hub) {\n",
       "                    window.__event_hub = {}\n",
       "                }\n",
       "                if (!window.__event_hub[container_id]) {\n",
       "                    window.__event_hub[container_id] = {}\n",
       "                }\n",
       "\n",
       "                if (!window.__send_event) {\n",
       "                    window.__send_event = {}\n",
       "                }\n",
       "                window.__send_event[container_id] = sendMessage.bind(this)\n",
       "\n",
       "                function sendMessage(message, uid, content) {\n",
       "                    return new Promise((resolve) => {\n",
       "                        this.model.send({\n",
       "                            message: `${message}:request`,\n",
       "                            body: {\n",
       "                                uid,\n",
       "                                content\n",
       "                            }\n",
       "                        })\n",
       "    \n",
       "                        var respMessageKey = `${message}:response`\n",
       "                        if (!window.__event_hub[container_id][respMessageKey]) {\n",
       "                            window.__event_hub[container_id][respMessageKey] = []\n",
       "                        }\n",
       "                        window.__event_hub[container_id][respMessageKey].push(callback)\n",
       "    \n",
       "                        function callback (response) {\n",
       "                            if (response.uid !== uid) {\n",
       "                                return\n",
       "                            }\n",
       "\n",
       "                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n",
       "                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n",
       "                            \n",
       "                            resolve(response)\n",
       "                        }\n",
       "                    })\n",
       "                }\n",
       "\n",
       "                function dispatchMessage (rawMessage) {\n",
       "                    var message = rawMessage.message\n",
       "                    var body = rawMessage.body\n",
       "\n",
       "                    if (!window.__event_hub[container_id][message]) {\n",
       "                        window.__event_hub[container_id][message] = []\n",
       "                    }\n",
       "                    var listeners = window.__event_hub[container_id][message]\n",
       "\n",
       "                    listeners.forEach(cb => {\n",
       "                        try {\n",
       "                            cb(body)\n",
       "                        } catch (e) {\n",
       "                            console.error(\"Unexpected error in listener\", e)\n",
       "                        }\n",
       "                    })\n",
       "\n",
       "                    console.log(body)\n",
       "                }\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = lib_url\n",
       "                this.el.appendChild(script)\n",
       "            }\n",
       "        });\n",
       "\n",
       "        return {\n",
       "            ValidateView\n",
       "        }\n",
       "    })\n",
       "} catch (e) {\n",
       "    console.log(\"create validation widget failed\", e)\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e689ca873f4f01991d6f9f567eae4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ValidateView(container_id='container_id_0c16a8c8-66bb-45c7-a0d2-1e2e83cad2b0_widget', env_json='{}', graph_jso…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #container_id_0c16a8c8-66bb-45c7-a0d2-1e2e83cad2b0_script svg.react-dag-editor-svg-container {\n",
       "            height: 800px;\n",
       "        }\n",
       "        </style>\n",
       "        <div id=\"container_id_0c16a8c8-66bb-45c7-a0d2-1e2e83cad2b0_script\"></div>\n",
       "        <script>\n",
       "            (function () {\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[\"0c16a8c8-66bb-45c7-a0d2-1e2e83cad2b0\"]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[\"0c16a8c8-66bb-45c7-a0d2-1e2e83cad2b0\"] = \"script\"\n",
       "                console.log(\"load as script\", Date.now())\n",
       "                window.render_container_id=\"container_id_0c16a8c8-66bb-45c7-a0d2-1e2e83cad2b0_script\";\n",
       "                window.graph_json={\"pipeline\": {\"name\": \"fasttext_pipeline\", \"data_references\": {\"THUCNews\": {\"dataset_id\": \"efa8f18c-9b9b-47f3-9630-de9002dc61aa\"}}, \"steps\": {\"574f634a\": {\"inputs\": {\"Input_dir\": {\"source\": \"THUCNews\"}}, \"outputs\": {\"Training_data_output\": {\"destination\": \"574f634a_Training_data_output\"}, \"Validation_data_output\": {\"destination\": \"574f634a_Validation_data_output\"}, \"Test_data_output\": {\"destination\": \"574f634a_Test_data_output\"}}, \"module\": {\"id\": \"7a7eb0ae-adb8-4c3a-a92e-dfaaaf79624b\", \"version\": \"0.0.43\"}, \"validate\": {\"error\": [], \"module_id\": \"7a7eb0ae-adb8-4c3a-a92e-dfaaaf79624b\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"Split Data Txt\", \"module_version\": \"0.0.43\"}}, \"82430532\": {\"inputs\": {\"Training_data_dir\": {\"source\": \"574f634a_Training_data_output\"}, \"Validation_data_dir\": {\"source\": \"574f634a_Validation_data_output\"}}, \"outputs\": {\"Trained_model_dir\": {\"destination\": \"82430532_Trained_model_dir\"}}, \"module\": {\"id\": \"b24b56c6-862b-47d2-a184-26b044a6bc70\", \"version\": \"0.0.41\"}, \"validate\": {\"error\": [], \"module_id\": \"b24b56c6-862b-47d2-a184-26b044a6bc70\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Train\", \"module_version\": \"0.0.41\"}}, \"ae3fec7f\": {\"inputs\": {\"Trained_model_dir\": {\"source\": \"82430532_Trained_model_dir\"}, \"Test_data_dir\": {\"source\": \"574f634a_Test_data_output\"}}, \"outputs\": {\"Model_testing_result\": {\"destination\": \"ae3fec7f_Model_testing_result\"}}, \"module\": {\"id\": \"2667937a-ffcd-4552-920d-f82efd1b0ed4\", \"version\": \"0.0.8\"}, \"validate\": {\"error\": [], \"module_id\": \"2667937a-ffcd-4552-920d-f82efd1b0ed4\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Evaluation\", \"module_version\": \"0.0.8\"}}, \"cc7030a5\": {\"inputs\": {\"Input_dir\": {\"source\": \"THUCNews\"}}, \"outputs\": {\"Training_data_output\": {\"destination\": \"cc7030a5_Training_data_output\"}, \"Validation_data_output\": {\"destination\": \"cc7030a5_Validation_data_output\"}, \"Test_data_output\": {\"destination\": \"cc7030a5_Test_data_output\"}}, \"module\": {\"id\": \"7a7eb0ae-adb8-4c3a-a92e-dfaaaf79624b\", \"version\": \"0.0.43\"}, \"validate\": {\"error\": [], \"module_id\": \"7a7eb0ae-adb8-4c3a-a92e-dfaaaf79624b\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"Split Data Txt\", \"module_version\": \"0.0.43\"}}, \"f534bc7e\": {\"inputs\": {\"Training_data_dir\": {\"source\": \"cc7030a5_Training_data_output\"}, \"Validation_data_dir\": {\"source\": \"cc7030a5_Validation_data_output\"}}, \"outputs\": {\"Trained_model_dir\": {\"destination\": \"f534bc7e_Trained_model_dir\"}}, \"module\": {\"id\": \"b24b56c6-862b-47d2-a184-26b044a6bc70\", \"version\": \"0.0.41\"}, \"validate\": {\"error\": [], \"module_id\": \"b24b56c6-862b-47d2-a184-26b044a6bc70\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Train\", \"module_version\": \"0.0.41\"}}, \"9375990a\": {\"inputs\": {\"Trained_model_dir\": {\"source\": \"f534bc7e_Trained_model_dir\"}, \"Test_data_dir\": {\"source\": \"cc7030a5_Test_data_output\"}}, \"outputs\": {\"Model_testing_result\": {\"destination\": \"9375990a_Model_testing_result\"}}, \"module\": {\"id\": \"2667937a-ffcd-4552-920d-f82efd1b0ed4\", \"version\": \"0.0.8\"}, \"validate\": {\"error\": [], \"module_id\": \"2667937a-ffcd-4552-920d-f82efd1b0ed4\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"FastText Evaluation\", \"module_version\": \"0.0.8\"}}, \"66b5523c\": {\"inputs\": {\"First_trained_model\": {\"source\": \"82430532_Trained_model_dir\"}, \"First_trained_result\": {\"source\": \"ae3fec7f_Model_testing_result\"}, \"Second_trained_model\": {\"source\": \"f534bc7e_Trained_model_dir\"}, \"Second_trained_result\": {\"source\": \"9375990a_Model_testing_result\"}}, \"outputs\": {}, \"module\": {\"id\": \"621834d8-6a64-45f6-9868-047ea45cf282\", \"version\": \"0.0.18\"}, \"validate\": {\"error\": [], \"module_id\": \"621834d8-6a64-45f6-9868-047ea45cf282\", \"namespace\": \"DesignerDRI_EASTUS\", \"module_name\": \"Compare Two Models\", \"module_version\": \"0.0.18\"}}}}, \"modules\": [{\"module_id\": \"7a7eb0ae-adb8-4c3a-a92e-dfaaaf79624b\", \"version\": \"0.0.43\", \"name\": \"Split Data Txt\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_dir\", \"label\": \"Input dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Training_data_output\", \"label\": \"Training data output\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}, {\"name\": \"Validation_data_output\", \"label\": \"Validation data output\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}, {\"name\": \"Test_data_output\", \"label\": \"Test data output\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}, {\"module_id\": \"b24b56c6-862b-47d2-a184-26b044a6bc70\", \"version\": \"0.0.41\", \"name\": \"FastText Train\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"Training_data_dir\", \"label\": \"Training data dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Validation_data_dir\", \"label\": \"Validation data dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Trained_model_dir\", \"label\": \"Trained model dir\", \"description\": null, \"data_type_id\": \"ModelDirectory\"}]}}, {\"module_id\": \"2667937a-ffcd-4552-920d-f82efd1b0ed4\", \"version\": \"0.0.8\", \"name\": \"FastText Evaluation\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"Trained_model_dir\", \"label\": \"Trained model dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Test_data_dir\", \"label\": \"Test data dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Model_testing_result\", \"label\": \"Model testing result\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}, {\"module_id\": \"621834d8-6a64-45f6-9868-047ea45cf282\", \"version\": \"0.0.18\", \"name\": \"Compare Two Models\", \"namespace\": \"DesignerDRI_EASTUS\", \"structured_interface\": {\"inputs\": [{\"name\": \"First_trained_model\", \"label\": \"First trained model\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"First_trained_result\", \"label\": \"First trained result\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Second_trained_model\", \"label\": \"Second trained model\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Second_trained_result\", \"label\": \"Second trained result\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"The_better_model\", \"label\": \"The better model\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}], \"datasources\": [{\"name\": \"THUCNews\", \"description\": \"THUCNews dataset is generated by filtering and filtering historical data     of Sina News RSS subscription channel from 2005 to 2011\", \"version\": \"1\", \"registered_id\": \"efa8f18c-9b9b-47f3-9630-de9002dc61aa\", \"saved_id\": \"8ece8ea8-1318-4d4d-8cac-2acb631feb85\", \"nodeId\": \"70286d9a-c269-31a9-bbba-13fbf3d37b70\"}], \"subGraphInfo\": [{\"name\": \"fasttext_pipeline\", \"description\": \"The pipeline that trains two fasttext models and output the better one\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"930783a4-61a6-47d4-bfdd-ed6188fc3d30\", \"pipeline_definition_id\": \"df349cfa-d63a-4af0-97cf-a510f0487bc4\", \"sub_graph_parameter_assignment\": [], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"66b5523c\"], \"sub_graph_default_data_store_nodes\": [\"66b5523c\"], \"inputs\": [], \"outputs\": []}, {\"name\": \"sub_pipeline\", \"description\": \"A sub pipeline including processes of data processing/training/evaluation\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"4d41e8ae-b109-49c1-b8f7-cdaf04a2402e\", \"parent_graph_id\": \"930783a4-61a6-47d4-bfdd-ed6188fc3d30\", \"pipeline_definition_id\": \"d1d769e3-bcae-4d6b-8ad8-18d4cbbc2512\", \"sub_graph_parameter_assignment\": [{\"parameter\": {\"name\": \"epochs\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"82430532\", \"parameter_name\": \"Epochs\"}]}, {\"parameter\": {\"name\": \"batch_size\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"82430532\", \"parameter_name\": \"Batch size\"}]}, {\"parameter\": {\"name\": \"max_len\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"82430532\", \"parameter_name\": \"Max len\"}]}], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"574f634a\", \"82430532\", \"ae3fec7f\"], \"sub_graph_default_data_store_nodes\": [], \"inputs\": [], \"outputs\": [{\"name\": \"model_testing_result\", \"internal\": [{\"node_id\": \"ae3fec7f\", \"port_name\": \"Model_testing_result\"}], \"external\": [{\"node_id\": \"66b5523c\", \"port_name\": \"First_trained_result\"}]}, {\"name\": \"trained_model_dir\", \"internal\": [{\"node_id\": \"82430532\", \"port_name\": \"Trained_model_dir\"}], \"external\": [{\"node_id\": \"ae3fec7f\", \"port_name\": \"Trained_model_dir\"}, {\"node_id\": \"66b5523c\", \"port_name\": \"First_trained_model\"}]}]}, {\"name\": \"sub_pipeline\", \"description\": \"A sub pipeline including processes of data processing/training/evaluation\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"72958fef-84ba-4c75-9d72-be24135fd2d8\", \"parent_graph_id\": \"930783a4-61a6-47d4-bfdd-ed6188fc3d30\", \"pipeline_definition_id\": \"d1d769e3-bcae-4d6b-8ad8-18d4cbbc2512\", \"sub_graph_parameter_assignment\": [{\"parameter\": {\"name\": \"epochs\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"f534bc7e\", \"parameter_name\": \"Epochs\"}]}, {\"parameter\": {\"name\": \"batch_size\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"f534bc7e\", \"parameter_name\": \"Batch size\"}]}, {\"parameter\": {\"name\": \"max_len\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"f534bc7e\", \"parameter_name\": \"Max len\"}]}], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"cc7030a5\", \"f534bc7e\", \"9375990a\"], \"sub_graph_default_data_store_nodes\": [], \"inputs\": [], \"outputs\": [{\"name\": \"model_testing_result\", \"internal\": [{\"node_id\": \"9375990a\", \"port_name\": \"Model_testing_result\"}], \"external\": [{\"node_id\": \"66b5523c\", \"port_name\": \"Second_trained_result\"}]}, {\"name\": \"trained_model_dir\", \"internal\": [{\"node_id\": \"f534bc7e\", \"port_name\": \"Trained_model_dir\"}], \"external\": [{\"node_id\": \"9375990a\", \"port_name\": \"Trained_model_dir\"}, {\"node_id\": \"66b5523c\", \"port_name\": \"Second_trained_model\"}]}]}], \"nodeIdToSubGraphIdMapping\": {\"574f634a\": \"4d41e8ae-b109-49c1-b8f7-cdaf04a2402e\", \"82430532\": \"4d41e8ae-b109-49c1-b8f7-cdaf04a2402e\", \"ae3fec7f\": \"4d41e8ae-b109-49c1-b8f7-cdaf04a2402e\", \"cc7030a5\": \"72958fef-84ba-4c75-9d72-be24135fd2d8\", \"f534bc7e\": \"72958fef-84ba-4c75-9d72-be24135fd2d8\", \"9375990a\": \"72958fef-84ba-4c75-9d72-be24135fd2d8\", \"66b5523c\": \"930783a4-61a6-47d4-bfdd-ed6188fc3d30\"}, \"subPipelineDefinition\": [{\"name\": \"fasttext_pipeline\", \"description\": \"The pipeline that trains two fasttext models and output the better one\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"pipeline_function_name\": \"fasttext_pipeline\", \"id\": \"df349cfa-d63a-4af0-97cf-a510f0487bc4\", \"from_module_name\": \"__main__\", \"parameter_list\": []}, {\"name\": \"sub_pipeline\", \"description\": \"A sub pipeline including processes of data processing/training/evaluation\", \"default_compute_target\": {\"name\": \"aml-compute-gpu\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"pipeline_function_name\": \"training_pipeline\", \"id\": \"d1d769e3-bcae-4d6b-8ad8-18d4cbbc2512\", \"from_module_name\": \"__main__\", \"parameter_list\": [{\"key\": \"epochs\"}, {\"key\": \"batch_size\"}, {\"key\": \"max_len\"}]}]};\n",
       "                window.graph_json_to_compare=undefined;\n",
       "                window.env_json={};\n",
       "                window.before_script = performance.now();\n",
       "                var script = document.createElement('script')\n",
       "                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.9/index.js\"\n",
       "                document.getElementById(\"container_id_0c16a8c8-66bb-45c7-a0d2-1e2e83cad2b0_script\").appendChild(script)\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_run.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a StepRun object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>984ce956-a725-4576-b95c-e746ff4e6889</td><td>azureml.StepRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/984ce956-a725-4576-b95c-e746ff4e6889?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "StepRun(Experiment: fasttext_pipeline,\n",
       "Id: 984ce956-a725-4576-b95c-e746ff4e6889,\n",
       "Type: azureml.StepRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain step_run_id from the visualization result.\n",
    "step_run_id = '984ce956-a725-4576-b95c-e746ff4e6889'\n",
    "step_run = pipeline_run.get_step_run(step_run_id)\n",
    "step_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the trained model from the port\n",
    "get_port() supports three kinds of names. For example,\n",
    "1. The better model \n",
    "2. the_better_model \n",
    "3. The_better_model\n",
    "\n",
    "These three names are considered the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading azureml/984ce956-a725-4576-b95c-e746ff4e6889/The_better_model/BestModel\n",
      "Downloading azureml/984ce956-a725-4576-b95c-e746ff4e6889/The_better_model/label.txt\n",
      "Downloading azureml/984ce956-a725-4576-b95c-e746ff4e6889/The_better_model/shared_params.json\n",
      "Downloading azureml/984ce956-a725-4576-b95c-e746ff4e6889/The_better_model/word_to_index.json\n",
      "Downloaded azureml/984ce956-a725-4576-b95c-e746ff4e6889/The_better_model/shared_params.json, 1 files out of an estimated total of 4\n",
      "Downloaded azureml/984ce956-a725-4576-b95c-e746ff4e6889/The_better_model/label.txt, 2 files out of an estimated total of 4\n",
      "Downloaded azureml/984ce956-a725-4576-b95c-e746ff4e6889/The_better_model/word_to_index.json, 3 files out of an estimated total of 4\n",
      "Downloaded azureml/984ce956-a725-4576-b95c-e746ff4e6889/The_better_model/BestModel, 4 files out of an estimated total of 4\n",
      "model save at: /tmp/azureml/984ce956-a725-4576-b95c-e746ff4e6889/The_better_model\n"
     ]
    }
   ],
   "source": [
    "port = step_run.get_port(name='The better model')\n",
    "saved_path = port.download(overwrite=True)\n",
    "print('model save at: {}'.format(saved_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the trained model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model fasttext_model_inference\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='DesignerDRI_EASTUS', subscription_id='74eccef0-4b8d-4f83-b5f9-fa100d155b22', resource_group='DesignerDRI'), name=fasttext_model_inference, id=fasttext_model_inference:1, version=1, tags={}, properties={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = saved_path\n",
    "model = Model.register(workspace, model_path=saved_path, model_name='fasttext_model_inference')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an Environment object for Inference Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200723.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"inference_environment\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"defaults\",\n",
       "                \"pytorch\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.6\",\n",
       "                \"pytorch==1.4.0\",\n",
       "                \"torchvision==0.5.0\",\n",
       "                \"cudatoolkit=10.1\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"--extra-index-url=https://azuremlsdktestpypi.azureedge.net/CLI-SDK-Runners-Validation/19783628\",\n",
       "                        \"azureml-defaults==0.1.0.19783628\",\n",
       "                        \"azureml-pipeline-wrapper==0.1.0.19783628\",\n",
       "                        \"scikit-learn==0.23.1\",\n",
       "                        \"tqdm\",\n",
       "                        \"pyarrow\",\n",
       "                        \"inference-schema\",\n",
       "                        \"jieba\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"azureml_64f6d31a23bc3bcf1633956b4d7745aa\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update = True when inference_environment.yaml has been updated manually.\n",
    "update = False\n",
    "env_list = Environment.list(workspace)\n",
    "name = 'inference_environment'\n",
    "# if the workspace doesn't contain the specific environment, then we'll register a new one.\n",
    "if update or not name in env_list:\n",
    "    # inference_environment.yaml describes dependencies your service needs.\n",
    "    file_path = 'deployment/inference_environment.yaml'\n",
    "    env = Environment.from_conda_specification(name=name, file_path=file_path)\n",
    "    env = env.register(workspace=workspace)\n",
    "else:\n",
    "    env = Environment.get(workspace=workspace, name=name)\n",
    "env    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an InferenceConfig object for deployment\n",
    "It represents the configuration settings for a custom environment used for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InferenceConfig(entry_script=fasttext_realtime_inference.py, runtime=None, conda_file=None, extra_docker_file_steps=None, source_directory=/mnt/batch/tasks/shared/LS_root/mounts/clusters/my-compute/code/Users/t-yangx/azureml-designer-demo/deployment, enable_gpu=None, base_image=None, base_image_registry=<azureml.core.container_registry.ContainerRegistry object at 0x7fd6281746a0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entry_script defines the processing logic for the input\n",
    "entry_script = 'fasttext_realtime_inference.py'\n",
    "# source_directory is the path to the folder that contains all files to create the service image\n",
    "source_directory = 'deployment'\n",
    "inference_config = InferenceConfig(entry_script=entry_script, source_directory=source_directory,\n",
    "                                   environment=env)\n",
    "inference_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelNotFound: Model with id fasttext_model_inference:2 not found in provided workspace\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model fasttext_model_inference:1 to /tmp/azureml_m71cnx6i/fasttext_model_inference/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry designerdriea2302d01.azurecr.io\n",
      "Logging into Docker registry designerdriea2302d01.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM designerdriea2302d01.azurecr.io/azureml/azureml_5164d757b6d7d5b9d70d699f7cd05edd\n",
      " ---> fa1b2cdac02c\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 0e996718da8f\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6Ijc0ZWNjZWYwLTRiOGQtNGY4My1iNWY5LWZhMTAwZDE1NWIyMiIsInJlc291cmNlR3JvdXBOYW1lIjoiZGVzaWduZXJkcmkiLCJhY2NvdW50TmFtZSI6ImRlc2lnbmVyZHJpX2Vhc3R1cyIsIndvcmtzcGFjZUlkIjoiZjZjNzVkZmYtMmMzMS00NDg2LTg0Y2ItMWRlZDMzODhlMzM3In0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in faa8a2ba07f9\n",
      " ---> afc5b8a6aba2\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpm9ps7sqa.py' /var/azureml-app/main.py\n",
      " ---> Running in 2744a1bef2b9\n",
      " ---> 7980eb0805c4\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 7ebad154d2e6\n",
      " ---> 1dd53abb20e3\n",
      "Successfully built 1dd53abb20e3\n",
      "Successfully tagged fasttext-deploy-to-local:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:66d665520ace693b557fbe28310dc1c64f4fff809ceab51324658f199824e4d6 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:8892\n",
      "running\n"
     ]
    }
   ],
   "source": [
    "service_name = 'fasttext-deploy-to-local'\n",
    "models = [model]\n",
    "port = 8892\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=port)\n",
    "service_locally = Model.deploy(workspace=workspace, name=service_name, models=models, inference_config=inference_config,\n",
    "                               deployment_config=deployment_config)\n",
    "service_locally.wait_for_deployment(show_output=True)\n",
    "print(service_locally.state)\n",
    "# When an error occurs, it is very helpful to use get_logs() to view the log\n",
    "# print(service_locally.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI (Azure Container Instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service_name = 'fasttext-deploy-to-aci'\n",
    "models = [model]\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "service_aci = Model.deploy(workspace, service_name, models=models, inference_config=inference_config,\n",
    "                           deployment_config=deployment_config, overwrite=True)\n",
    "service_aci.wait_for_deployment(show_output=True)\n",
    "print(service_aci.state)\n",
    "# When an error occurs, it is very helpful to use get_logs() to view the log\n",
    "#print(service_aci.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to AKS (Azure Kubernetes Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AksCompute(workspace=Workspace.create(name='DesignerDRI_EASTUS', subscription_id='74eccef0-4b8d-4f83-b5f9-fa100d155b22', resource_group='DesignerDRI'), name=attached-aks, id=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourceGroups/DesignerDRI/providers/Microsoft.MachineLearningServices/workspaces/DesignerDRI_EASTUS/computes/attached-aks, type=AKS, provisioning_state=Succeeded, location=eastus, tags=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose an inference cluster\n",
    "name = 'attached-aks'\n",
    "compute_target_name_list = [target.name for target in AksCompute.list(workspace)]\n",
    "if not name in compute_target_name_list:\n",
    "    aks_resource_group = 'AmlStudioV2DRI'\n",
    "    cluster_name = 'aks-dev-6node33512023a'\n",
    "    attach_config = AksCompute.attach_configuration(resource_group=aks_resource_group, cluster_name=cluster_name)\n",
    "    aks_target = ComputeTarget.attach(workspace, name, attach_config)\n",
    "    aks_target.wait_for_completion(show_output=True)\n",
    "aks_target = AksCompute(workspace, name)\n",
    "aks_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.........\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "# deploy to AKS (Azure Kubernetes Service)\n",
    "service_name = 'fasttext-deploy-to-aks'\n",
    "models = [model]\n",
    "# Only one type of Auth may be enabled\n",
    "token_auth_enabled = True\n",
    "auth_enabled = False if token_auth_enabled else True\n",
    "\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores=1, memory_gb=1,\n",
    "                                                       token_auth_enabled=token_auth_enabled,\n",
    "                                                       auth_enabled=auth_enabled)\n",
    "service_aks = Model.deploy(workspace, service_name, models, inference_config, deployment_config, aks_target, overwrite=True)\n",
    "service_aks.wait_for_deployment(show_output=True)\n",
    "print(service_aks.state)\n",
    "# When an error occurs, it is very helpful to use get_logs() to view the log\n",
    "#print(service_aks.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# Get a token to authenticate to the compute instance from remote\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "\n",
    "# Create and submit a request using the auth header\n",
    "headers = auth_header\n",
    "# Add content type header\n",
    "headers.update({'Content-Type': 'application/json'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consume the service deployed to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8892/score\n",
      "<Response [200]>\n",
      "b'\"education\"'\n",
      "education\n"
     ]
    }
   ],
   "source": [
    "# your input\n",
    "standard_sample_input = {'param': {'input_sentence': '受疫情影响, 很多学生不得不在家上课'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "\n",
    "# consume the service deployed to local\n",
    "service = service_locally\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response)\n",
    "print(response.content)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consume the service deployed to ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://acc8fdb1-e73f-4927-8dd5-909e74306db1.eastus.azurecontainer.io/score\n",
      "<Response [200]>\n",
      "b'\"stock\"'\n",
      "stock\n"
     ]
    }
   ],
   "source": [
    "# your input\n",
    "standard_sample_input = {'param': {'input_sentence': '股市有风险, 请谨慎尝试'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "\n",
    "# consume the service deployed to ACI\n",
    "service = service_aci\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response)\n",
    "print(response.content)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consume the service deployed to AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://52.170.37.14:80/api/v1/service/fasttext-deploy-to-aks/score\n",
      "<Response [200]>\n",
      "b'\"game\"'\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "# your input\n",
    "standard_sample_input = {'param': {'input_sentence': '奥沙利文夺得2020年台球世锦赛冠军'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "\n",
    "# consume the service deployed to AKS\n",
    "service = service_aks\n",
    "token, refresh_by = service.get_token()\n",
    "headers['Authorization']=f'Bearer {token}'\n",
    "\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response)\n",
    "print(response.content)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasttext",
   "language": "python",
   "name": "fasttext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
