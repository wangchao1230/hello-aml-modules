{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License.\n",
    "\n",
    "# NYC Taxi Data Regression Model\n",
    "This is an Azure Machine Learning Pipelines version of two-part tutorial (Part 1, Part 2) available for Azure Machine Learning.\n",
    "\n",
    "You can combine the two part tutorial into one using AzureML Pipelines as Pipelines provide a way to stitch together various steps involved (like data preparation and training in this case) in a machine learning workflow.\n",
    "\n",
    "In this notebook, you learn how to prepare data for regression modeling by using open source library pandas. You run various transformations to filter and combine two different NYC taxi datasets. Once you prepare the NYC taxi data for regression modeling, then you will use AutoMLStep available with Azure Machine Learning Pipelines to define your machine learning goals and constraints as well as to launch the automated machine learning process. The automated machine learning technique iterates over many combinations of algorithms and hyperparameters until it finds the best model based on your criterion.\n",
    "\n",
    "After you complete building the model, you can predict the cost of a taxi trip by training a model on data features. These features include the pickup day and time, the number of passengers, and the pickup location.\n",
    "\n",
    "## Prerequisite\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at https://github.com/Azure/MachineLearningNotebooks first if you haven't. This sets you up with a working config file that has information on your workspace, subscription id, etc.\n",
    "\n",
    "## Prepare data for regression modeling\n",
    "First, we will prepare data for regression modeling. We will leverage the convenience of Azure Open Datasets along with the power of Azure Machine Learning service to create a regression model to predict NYC taxi fare prices. Perform ```pip install azureml-opendatasets``` to get the open dataset package. The Open Datasets package contains a class representing each data source (NycTlcGreen and NycTlcYellow) to easily filter date parameters before downloading.\n",
    "\n",
    "### Load data\n",
    "Begin by creating a dataframe to hold the taxi data. When working in a non-Spark environment, Open Datasets only allows downloading one month of data at a time with certain classes to avoid MemoryError with large datasets. To download a year of taxi data, iteratively fetch one month at a time, and before appending it to green_df_raw, randomly sample 500 records from each month to avoid bloating the dataframe. Then preview the data. To keep this process short, we are sampling data of only 1 month.\n",
    "\n",
    "Note: Open Datasets has mirroring classes for working in Spark environments where data size and memory aren't a concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp5xidbto8\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\green\\puYear=2016\\puMonth=1\\part-00119-tid-4753095944193949832-fee7e113-666d-4114-9fcb-bcd3046479f3-2689-1.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "from azureml.opendatasets import NycTlcGreen, NycTlcYellow\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "green_df_raw = pd.DataFrame([])\n",
    "start = datetime.strptime(\"1/1/2016\",\"%m/%d/%Y\")\n",
    "end = datetime.strptime(\"1/31/2016\",\"%m/%d/%Y\")\n",
    "\n",
    "number_of_months = 1\n",
    "sample_size = 5000\n",
    "\n",
    "for sample_month in range(number_of_months):\n",
    "    temp_df_green = NycTlcGreen(start + relativedelta(months=sample_month), end + relativedelta(months=sample_month)) \\\n",
    "        .to_pandas_dataframe()\n",
    "    green_df_raw = green_df_raw.append(temp_df_green.sample(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00000-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426339-90.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00001-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426336-89.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00002-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426334-91.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00003-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426340-87.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00004-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426331-88.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00005-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426324-89.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00006-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426326-88.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00007-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426332-90.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00008-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426341-90.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00009-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426325-88.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00010-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426335-89.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00011-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426338-89.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00012-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426337-89.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00013-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426327-89.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00014-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426330-90.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00015-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426342-89.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00016-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426328-88.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00017-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426323-90.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00018-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426329-90.c000.snappy.parquet\n",
      "[Info] read from C:\\Users\\nashangg\\AppData\\Local\\Temp\\tmp69_j68c1\\https%3A\\%2Fazureopendatastorage.azurefd.net\\nyctlc\\yellow\\puYear=2016\\puMonth=1\\part-00019-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426333-88.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "yellow_df_raw = pd.DataFrame([])\n",
    "start = datetime.strptime(\"1/1/2016\",\"%m/%d/%Y\")\n",
    "end = datetime.strptime(\"1/31/2016\",\"%m/%d/%Y\")\n",
    "\n",
    "sample_size = 500\n",
    "\n",
    "for sample_month in range(number_of_months):\n",
    "    temp_df_yellow = NycTlcYellow(start + relativedelta(months=sample_month), end + relativedelta(months=sample_month)) \\\n",
    "        .to_pandas_dataframe()\n",
    "    yellow_df_raw = yellow_df_raw.append(temp_df_yellow.sample(sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>lpepPickupDatetime</th>\n",
       "      <th>lpepDropoffDatetime</th>\n",
       "      <th>passengerCount</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>puLocationId</th>\n",
       "      <th>doLocationId</th>\n",
       "      <th>pickupLongitude</th>\n",
       "      <th>pickupLatitude</th>\n",
       "      <th>dropoffLongitude</th>\n",
       "      <th>...</th>\n",
       "      <th>paymentType</th>\n",
       "      <th>fareAmount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mtaTax</th>\n",
       "      <th>improvementSurcharge</th>\n",
       "      <th>tipAmount</th>\n",
       "      <th>tollsAmount</th>\n",
       "      <th>ehailFee</th>\n",
       "      <th>totalAmount</th>\n",
       "      <th>tripType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103431</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-02 21:36:49</td>\n",
       "      <td>2016-01-02 22:01:43</td>\n",
       "      <td>1</td>\n",
       "      <td>6.33</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.994255</td>\n",
       "      <td>40.703114</td>\n",
       "      <td>-73.991791</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.56</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506056</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-11 14:32:13</td>\n",
       "      <td>2016-01-11 14:38:26</td>\n",
       "      <td>2</td>\n",
       "      <td>1.41</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.952347</td>\n",
       "      <td>40.789829</td>\n",
       "      <td>-73.939316</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.76</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586952</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-26 18:23:49</td>\n",
       "      <td>2016-01-26 18:26:15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.37</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.961739</td>\n",
       "      <td>40.805851</td>\n",
       "      <td>-73.961227</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947971</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-15 23:37:16</td>\n",
       "      <td>2016-01-15 23:56:37</td>\n",
       "      <td>1</td>\n",
       "      <td>7.87</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.903351</td>\n",
       "      <td>40.745506</td>\n",
       "      <td>-73.981400</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758472</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-10 01:47:03</td>\n",
       "      <td>2016-01-10 02:14:19</td>\n",
       "      <td>1</td>\n",
       "      <td>16.74</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.920029</td>\n",
       "      <td>40.768124</td>\n",
       "      <td>-73.862610</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         vendorID  lpepPickupDatetime lpepDropoffDatetime  passengerCount  \\\n",
       "1103431         2 2016-01-02 21:36:49 2016-01-02 22:01:43               1   \n",
       "506056          2 2016-01-11 14:32:13 2016-01-11 14:38:26               2   \n",
       "586952          2 2016-01-26 18:23:49 2016-01-26 18:26:15               1   \n",
       "947971          2 2016-01-15 23:37:16 2016-01-15 23:56:37               1   \n",
       "758472          2 2016-01-10 01:47:03 2016-01-10 02:14:19               1   \n",
       "\n",
       "         tripDistance puLocationId doLocationId  pickupLongitude  \\\n",
       "1103431          6.33         None         None       -73.994255   \n",
       "506056           1.41         None         None       -73.952347   \n",
       "586952           0.37         None         None       -73.961739   \n",
       "947971           7.87         None         None       -73.903351   \n",
       "758472          16.74         None         None       -73.920029   \n",
       "\n",
       "         pickupLatitude  dropoffLongitude  ...  paymentType  fareAmount extra  \\\n",
       "1103431       40.703114        -73.991791  ...            1        22.5   0.5   \n",
       "506056        40.789829        -73.939316  ...            1         6.5   0.0   \n",
       "586952        40.805851        -73.961227  ...            1         3.5   1.0   \n",
       "947971        40.745506        -73.981400  ...            1        24.5   0.5   \n",
       "758472        40.768124        -73.862610  ...            2        45.5   0.5   \n",
       "\n",
       "         mtaTax  improvementSurcharge  tipAmount  tollsAmount ehailFee  \\\n",
       "1103431     0.5                   0.3       4.76          0.0      NaN   \n",
       "506056      0.5                   0.3       1.46          0.0      NaN   \n",
       "586952      0.5                   0.3       0.58          0.0      NaN   \n",
       "947971      0.5                   0.3       5.16          0.0      NaN   \n",
       "758472      0.5                   0.3       0.00          0.0      NaN   \n",
       "\n",
       "         totalAmount  tripType  \n",
       "1103431        28.56       1.0  \n",
       "506056          8.76       1.0  \n",
       "586952          5.88       1.0  \n",
       "947971         30.96       1.0  \n",
       "758472         46.80       1.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorID</th>\n",
       "      <th>tpepPickupDateTime</th>\n",
       "      <th>tpepDropoffDateTime</th>\n",
       "      <th>passengerCount</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>puLocationId</th>\n",
       "      <th>doLocationId</th>\n",
       "      <th>startLon</th>\n",
       "      <th>startLat</th>\n",
       "      <th>endLon</th>\n",
       "      <th>...</th>\n",
       "      <th>rateCodeId</th>\n",
       "      <th>storeAndFwdFlag</th>\n",
       "      <th>paymentType</th>\n",
       "      <th>fareAmount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mtaTax</th>\n",
       "      <th>improvementSurcharge</th>\n",
       "      <th>tipAmount</th>\n",
       "      <th>tollsAmount</th>\n",
       "      <th>totalAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194079</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-22 07:48:42</td>\n",
       "      <td>2016-01-22 07:55:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.966454</td>\n",
       "      <td>40.804737</td>\n",
       "      <td>-73.966919</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435551</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-12 05:23:40</td>\n",
       "      <td>2016-01-12 05:46:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.36</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.989029</td>\n",
       "      <td>40.744640</td>\n",
       "      <td>-73.787445</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.67</td>\n",
       "      <td>5.54</td>\n",
       "      <td>70.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227970</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-06 20:49:44</td>\n",
       "      <td>2016-01-06 21:14:15</td>\n",
       "      <td>1</td>\n",
       "      <td>10.80</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.870773</td>\n",
       "      <td>40.773750</td>\n",
       "      <td>-73.981216</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.54</td>\n",
       "      <td>43.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109059</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-14 14:32:06</td>\n",
       "      <td>2016-01-14 14:55:56</td>\n",
       "      <td>1</td>\n",
       "      <td>4.22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.990150</td>\n",
       "      <td>40.756538</td>\n",
       "      <td>-73.947029</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88893</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-26 22:24:38</td>\n",
       "      <td>2016-01-26 22:35:49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.969139</td>\n",
       "      <td>40.755104</td>\n",
       "      <td>-73.980156</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vendorID  tpepPickupDateTime tpepDropoffDateTime  passengerCount  \\\n",
       "194079        1 2016-01-22 07:48:42 2016-01-22 07:55:20               1   \n",
       "435551        2 2016-01-12 05:23:40 2016-01-12 05:46:00               1   \n",
       "227970        1 2016-01-06 20:49:44 2016-01-06 21:14:15               1   \n",
       "109059        2 2016-01-14 14:32:06 2016-01-14 14:55:56               1   \n",
       "88893         1 2016-01-26 22:24:38 2016-01-26 22:35:49               1   \n",
       "\n",
       "        tripDistance puLocationId doLocationId   startLon   startLat  \\\n",
       "194079          0.90         None         None -73.966454  40.804737   \n",
       "435551         17.36         None         None -73.989029  40.744640   \n",
       "227970         10.80         None         None -73.870773  40.773750   \n",
       "109059          4.22         None         None -73.990150  40.756538   \n",
       "88893           1.10         None         None -73.969139  40.755104   \n",
       "\n",
       "           endLon  ...  rateCodeId  storeAndFwdFlag paymentType fareAmount  \\\n",
       "194079 -73.966919  ...           1                N           2        6.5   \n",
       "435551 -73.787445  ...           2                N           1       52.0   \n",
       "227970 -73.981216  ...           1                N           1       32.0   \n",
       "109059 -73.947029  ...           1                N           2       18.5   \n",
       "88893  -73.980156  ...           1                N           1        8.5   \n",
       "\n",
       "        extra  mtaTax  improvementSurcharge tipAmount  tollsAmount  \\\n",
       "194079    0.0     0.5                   0.3      0.00         0.00   \n",
       "435551    0.0     0.5                   0.3     11.67         5.54   \n",
       "227970    0.5     0.5                   0.3      5.00         5.54   \n",
       "109059    0.0     0.5                   0.3      0.00         0.00   \n",
       "88893     0.5     0.5                   0.3      2.00         0.00   \n",
       "\n",
       "        totalAmount  \n",
       "194079         7.30  \n",
       "435551        70.01  \n",
       "227970        43.84  \n",
       "109059        19.30  \n",
       "88893         11.80  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(green_df_raw.head(5))\n",
    "display(yellow_df_raw.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data locally and then upload to Azure Blob\n",
    "This is a one-time process to save the dave in the default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to local folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataDir = \"data\"\n",
    "\n",
    "if not os.path.exists(dataDir):\n",
    "    os.mkdir(dataDir)\n",
    "\n",
    "greenDir = dataDir + \"/green\"\n",
    "yelloDir = dataDir + \"/yellow\"\n",
    "\n",
    "if not os.path.exists(greenDir):\n",
    "    os.mkdir(greenDir)\n",
    "    \n",
    "if not os.path.exists(yelloDir):\n",
    "    os.mkdir(yelloDir)\n",
    "    \n",
    "greenTaxiData = greenDir + \"/unprepared.parquet\"\n",
    "yellowTaxiData = yelloDir + \"/unprepared.parquet\"\n",
    "\n",
    "green_df_raw.to_csv(greenTaxiData, index=False)\n",
    "yellow_df_raw.to_csv(yellowTaxiData, index=False)\n",
    "\n",
    "print(\"Data written to local folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace: DesignerTest-EUS\n",
      "Region: eastus\n",
      "Uploading an estimated of 1 files\n",
      "Uploading data/green/unprepared.parquet\n",
      "Uploaded data/green/unprepared.parquet, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Uploading an estimated of 1 files\n",
      "Uploading data/yellow/unprepared.parquet\n",
      "Uploaded data/yellow/unprepared.parquet, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Upload calls completed.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace: \" + ws.name, \"Region: \" + ws.location, sep = '\\n')\n",
    "\n",
    "# Default datastore\n",
    "default_store = ws.get_default_datastore() \n",
    "\n",
    "default_store.upload_files([greenTaxiData], \n",
    "                           target_path = 'green', \n",
    "                           overwrite = True, \n",
    "                           show_progress = True)\n",
    "\n",
    "default_store.upload_files([yellowTaxiData], \n",
    "                           target_path = 'yellow', \n",
    "                           overwrite = True, \n",
    "                           show_progress = True)\n",
    "\n",
    "print(\"Upload calls completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and register datasets\n",
    "By creating a dataset, you create a reference to the data source location. If you applied any subsetting transformations to the dataset, they will be stored in the dataset as well. You can learn more about the what subsetting capabilities are supported by referring to our documentation. The data remains in its existing location, so no extra storage cost is incurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "green_taxi_data = Dataset.Tabular.from_delimited_files(default_store.path('green/unprepared.parquet'))\n",
    "yellow_taxi_data = Dataset.Tabular.from_delimited_files(default_store.path('yellow/unprepared.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the taxi datasets with the workspace so that you can reuse them in other experiments or share with your colleagues who have access to your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_taxi_data = green_taxi_data.register(ws, 'green_taxi_data', create_new_version=True)\n",
    "yellow_taxi_data = yellow_taxi_data.register(ws, 'yellow_taxi_data', create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Compute\n",
    "#### Create new or use an existing compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "amlcompute_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aml_compute = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           max_nodes=4)\n",
    "    aml_compute = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "aml_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "Now we will prepare for regression modeling by using pandas. We run various transformations to filter and combine two different NYC taxi datasets.\n",
    "\n",
    "We achieve this by creating a separate step for each transformation as this allows us to reuse the steps and saves us from running all over again in case of any change. We will keep data preparation scripts in one subfolder and training scripts in another.\n",
    "\n",
    "> The best practice is to use separate folders for scripts and its dependent files for each step and specify that folder as the source_directory for the step. This helps reduce the size of the snapshot created for the step (only the specific folder is snapshotted). Since changes in any files in the source_directory would trigger a re-upload of the snapshot, this helps keep the reuse of the step when there are no changes in the source_directory of the step.\n",
    "#### Define Useful Columns\n",
    "Here we are defining a set of \"useful\" columns for both Green and Yellow taxi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vendorID', 'lpepPickupDatetime', 'lpepDropoffDatetime',\n",
       "       'passengerCount', 'tripDistance', 'puLocationId', 'doLocationId',\n",
       "       'pickupLongitude', 'pickupLatitude', 'dropoffLongitude',\n",
       "       'dropoffLatitude', 'rateCodeID', 'storeAndFwdFlag', 'paymentType',\n",
       "       'fareAmount', 'extra', 'mtaTax', 'improvementSurcharge', 'tipAmount',\n",
       "       'tollsAmount', 'ehailFee', 'totalAmount', 'tripType'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['vendorID', 'tpepPickupDateTime', 'tpepDropoffDateTime',\n",
       "       'passengerCount', 'tripDistance', 'puLocationId', 'doLocationId',\n",
       "       'startLon', 'startLat', 'endLon', 'endLat', 'rateCodeId',\n",
       "       'storeAndFwdFlag', 'paymentType', 'fareAmount', 'extra', 'mtaTax',\n",
       "       'improvementSurcharge', 'tipAmount', 'tollsAmount', 'totalAmount'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful columns defined.\n"
     ]
    }
   ],
   "source": [
    "display(green_df_raw.columns)\n",
    "display(yellow_df_raw.columns)\n",
    "\n",
    "# useful columns needed for the Azure Machine Learning NYC Taxi tutorial\n",
    "useful_columns = str([\"cost\", \"distance\", \"dropoff_datetime\", \"dropoff_latitude\", \n",
    "                      \"dropoff_longitude\", \"passengers\", \"pickup_datetime\", \n",
    "                      \"pickup_latitude\", \"pickup_longitude\", \"store_forward\", \"vendor\"]).replace(\",\", \";\")\n",
    "\n",
    "print(\"Useful columns defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanse Green taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.component import Component\n",
    "\n",
    "cleansing_component_func = Component.from_yaml(ws, os.path.join('nyc-taxi-data-regression-model-building', 'cleanse', 'cleanse_spec.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleansing_step_green created.\n"
     ]
    }
   ],
   "source": [
    "green_columns = str({ \n",
    "    \"vendorID\": \"vendor\",\n",
    "    \"lpepPickupDatetime\": \"pickup_datetime\",\n",
    "    \"lpepDropoffDatetime\": \"dropoff_datetime\",\n",
    "    \"storeAndFwdFlag\": \"store_forward\",\n",
    "    \"pickupLongitude\": \"pickup_longitude\",\n",
    "    \"pickupLatitude\": \"pickup_latitude\",\n",
    "    \"dropoffLongitude\": \"dropoff_longitude\",\n",
    "    \"dropoffLatitude\": \"dropoff_latitude\",\n",
    "    \"passengerCount\": \"passengers\",\n",
    "    \"fareAmount\": \"cost\",\n",
    "    \"tripDistance\": \"distance\"\n",
    "}).replace(\",\", \";\")\n",
    "\n",
    "cleansing_step_green = cleansing_component_func(\n",
    "    raw_data=green_taxi_data.as_named_input('raw_data'),\n",
    "    useful_columns=useful_columns,\n",
    "    columns=green_columns)\n",
    "\n",
    "print(\"cleansing_step_green created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanse Yellow taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleansing_step_yellow created.\n"
     ]
    }
   ],
   "source": [
    "yellow_columns = str({\n",
    "    \"vendorID\": \"vendor\",\n",
    "    \"tpepPickupDateTime\": \"pickup_datetime\",\n",
    "    \"tpepDropoffDateTime\": \"dropoff_datetime\",\n",
    "    \"storeAndFwdFlag\": \"store_forward\",\n",
    "    \"startLon\": \"pickup_longitude\",\n",
    "    \"startLat\": \"pickup_latitude\",\n",
    "    \"endLon\": \"dropoff_longitude\",\n",
    "    \"endLat\": \"dropoff_latitude\",\n",
    "    \"passengerCount\": \"passengers\",\n",
    "    \"fareAmount\": \"cost\",\n",
    "    \"tripDistance\": \"distance\"\n",
    "}).replace(\",\", \";\")\n",
    "\n",
    "cleansing_step_yellow = cleansing_component_func(\n",
    "    raw_data=yellow_taxi_data.as_named_input('raw_data'),\n",
    "    useful_columns=useful_columns,\n",
    "    columns=yellow_columns)\n",
    "\n",
    "print(\"cleansing_step_yellow created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge cleansed Green and Yellow datasets\n",
    "We are creating a single data source by merging the cleansed versions of Green and Yellow taxi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_component_func = Component.from_yaml(ws, os.path.join('nyc-taxi-data-regression-model-building', 'merge', 'merge_spec.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging_step created.\n"
     ]
    }
   ],
   "source": [
    "merging_step = merging_component_func(\n",
    "    cleansed_green_data=cleansing_step_green.outputs.output_cleanse,\n",
    "    cleansed_yellow_data=cleansing_step_yellow.outputs.output_cleanse)\n",
    "\n",
    "print(\"merging_step created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter data\n",
    "This step filters out coordinates for locations that are outside the city border. We use a TypeConverter object to change the latitude and longitude fields to decimal type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_component_func = Component.from_yaml(ws, os.path.join('nyc-taxi-data-regression-model-building', 'filter', 'filter_spec.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_step created.\n"
     ]
    }
   ],
   "source": [
    "filter_step = filter_component_func(merged_data=merging_step.outputs.output_merge)\n",
    "\n",
    "print(\"filter_step created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize data\n",
    "In this step, we split the pickup and dropoff datetime values into the respective date and time columns and then we rename the columns to use meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_component_func = Component.from_yaml(ws, os.path.join('nyc-taxi-data-regression-model-building', 'normalize', 'normalize_spec.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize_step created.\n"
     ]
    }
   ],
   "source": [
    "normalize_step = normalize_component_func(filtered_data=filter_step.outputs.output_filter)\n",
    "\n",
    "print(\"normalize_step created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform data\n",
    "Transform the normalized taxi data to final required format. This steps does the following:\n",
    "\n",
    "- Split the pickup and dropoff date further into the day of the week, day of the month, and month values.\n",
    "- To get the day of the week value, uses the derive_column_by_example() function. The function takes an array parameter of example objects that define the input data, and the preferred output. The function automatically determines the preferred transformation. For the pickup and dropoff time columns, split the time into the hour, minute, and second by using the split_column_by_example() function with no example parameter.\n",
    "- After new features are generated, use the drop_columns() function to delete the original fields as the newly generated features are preferred.\n",
    "- Rename the rest of the fields to use meaningful descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_component_func = Component.from_yaml(ws, os.path.join('nyc-taxi-data-regression-model-building', 'transform', 'transform_spec.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_step created.\n"
     ]
    }
   ],
   "source": [
    "transform_step = transform_component_func(normalized_data=normalize_step.outputs.output_normalize)\n",
    "\n",
    "print(\"transform_step created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train and test sets\n",
    "This function segregates the data into dataset for model training and dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_split_component_func = Component.from_yaml(ws, os.path.join('nyc-taxi-data-regression-model-building', 'train_test_split', 'train_test_split_spec.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train_split_step created.\n"
     ]
    }
   ],
   "source": [
    "test_train_split_step = test_train_split_component_func(transformed_data=transform_step.outputs.output_transform)\n",
    "\n",
    "print(\"test_train_split_step created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add regression steps\n",
    "TODO: use AutoML step in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns_func = Component.load(ws, namespace='azureml', name='Select Columns in Dataset')\n",
    "linear_regression_func = Component.load(ws, namespace='azureml', name='Linear Regression')\n",
    "train_model_func = Component.load(ws, namespace='azureml', name='Train Model')\n",
    "score_model_func = Component.load(ws, namespace='azureml', name='Score Model')\n",
    "evaluate_model_func = Component.load(ws, namespace='azureml', name='Evaluate Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns_step = select_columns_func(\n",
    "    dataset=test_train_split_step.outputs.output_split_train,\n",
    "    select_columns='{\"isFilter\":true,\"rules\":[{\"exclude\":false,\"ruleType\":\"ColumnNames\",\"columns\":[\"pickup_weekday\",\"pickup_hour\",\"distance\",\"passengers\",\"vendor\",\"cost\"]}]}')\n",
    "linear_regression_step = linear_regression_func(\n",
    "    solution_method='Ordinary Least Squares',\n",
    "    l2_regularization_weight=0.001,\n",
    "    include_intercept_term=True)\n",
    "train_model_step = train_model_func(\n",
    "    dataset=select_columns_step.outputs.results_dataset,\n",
    "    label_column='{\"isFilter\":true,\"rules\":[{\"exclude\":false,\"ruleType\":\"ColumnNames\",\"columns\":[\"cost\"]}]}',\n",
    "    untrained_model=linear_regression_step.outputs.untrained_model)\n",
    "score_model_step = score_model_func(\n",
    "    trained_model=train_model_step.outputs.trained_model,\n",
    "    dataset=test_train_split_step.outputs.output_split_test,\n",
    "    append_score_columns_to_output=True)\n",
    "evaluate_model_step = evaluate_model_func(scored_dataset=score_model_step.outputs.scored_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.component import PipelineComponent\n",
    "\n",
    "pipeline = PipelineComponent(\n",
    "    [cleansing_step_green,\n",
    "     cleansing_step_yellow,\n",
    "     merging_step,\n",
    "     filter_step,\n",
    "     normalize_step,\n",
    "     transform_step,\n",
    "     test_train_split_step,\n",
    "     select_columns_step,\n",
    "     linear_regression_step,\n",
    "     train_model_step,\n",
    "     score_model_step,\n",
    "     evaluate_model_step],\n",
    "    default_compute_target='cpu-cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun 8ca8c878-e176-4d8b-a903-411842005dc7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/NYCTaxi_Tutorial_Pipelines/runs/8ca8c878-e176-4d8b-a903-411842005dc7?wsid=/subscriptions/4faaaf21-663f-4391-96fd-47197c630979/resourcegroups/DesignerTestRG/workspaces/DesignerTest-EUS\n",
      "PipelineRunId: 8ca8c878-e176-4d8b-a903-411842005dc7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/NYCTaxi_Tutorial_Pipelines/runs/8ca8c878-e176-4d8b-a903-411842005dc7?wsid=/subscriptions/4faaaf21-663f-4391-96fd-47197c630979/resourcegroups/DesignerTestRG/workspaces/DesignerTest-EUS\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_can_visualize' from 'azureml.component._utils' (c:\\users\\nashangg\\source\\repos\\azuremlcli\\src\\azureml-component\\azureml\\component\\_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-9f2cc6da24c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NYCTaxi_Tutorial_Pipelines'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\nashangg\\source\\repos\\azuremlcli\\src\\azureml-component\\azureml\\component\\_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m                                                activity_type, custom_dimensions, flush, record_inner_depth) as al:\n\u001b[0;32m    225\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;34m'request_id'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mextracted_dimension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nashangg\\source\\repos\\azuremlcli\\src\\azureml-component\\azureml\\component\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, show_graph, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \"\"\"\n\u001b[0;32m    355\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_pipeline_run\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_pipeline_run_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_step_run_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nashangg\\source\\repos\\azuremlcli\\src\\azureml-component\\azureml\\component\\run.py\u001b[0m in \u001b[0;36m_wait_for_pipeline_run_completion\u001b[1;34m(self, show_output, show_graph, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[0mshow_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[0mshow_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshow_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[0mvisualizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_visualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nashangg\\source\\repos\\azuremlcli\\src\\azureml-component\\azureml\\component\\run.py\u001b[0m in \u001b[0;36m_visualize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVISUALIZATION_NOT_SUPPORTED_MESSAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_visualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nashangg\\source\\repos\\azuremlcli\\src\\azureml-component\\azureml\\component\\_widgets\\_visualize.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0muuid\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0muuid4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loggerfactory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_can_visualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mAZUREML_SDK_UI_VERSION_SET_ENV_NAME\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"AZUREML_SDK_UI_VERSION_SET\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_can_visualize' from 'azureml.component._utils' (c:\\users\\nashangg\\source\\repos\\azuremlcli\\src\\azureml-component\\azureml\\component\\_utils.py)"
     ]
    }
   ],
   "source": [
    "run = pipeline.submit(experiment_name='NYCTaxi_Tutorial_Pipelines')\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aml)",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
