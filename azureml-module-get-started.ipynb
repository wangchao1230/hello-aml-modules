{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build AML Pipeline with azureml modules\n",
    "\n",
    "In this tutorial you will learn how to work with Azure ML module:\n",
    "\n",
    "1. Setup enrivonment - install module CLI and module/pipeline SDK\n",
    "2. Register a few sample modules into your aml workspace using CLI\n",
    "3. Use module/pipeline SDK to create a pipeline with modules registered in step 2\n",
    "\n",
    "## Prerequisite\n",
    "* Install Azure CLI, please follow [the Azure CLI installation instructions](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest) to install."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment\n",
    "* Install Azure CLI AML extension which includes the _module_ command group\n",
    "* Install Azure ML SDK including the APIs to work with _module_ and _pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uninstall azure-cli-ml (the `az ml` commands)\n",
    "!az extension remove -n azure-cli-ml \n",
    "\n",
    "# Install local version of azure-cli-ml (which includes `az ml module` commands)\n",
    "!az extension add --source https://azuremlsdktestpypi.azureedge.net/CLI-SDK-Runners-Validation/13405526/azure_cli_ml-0.1.0.13405526-py3-none-any.whl --pip-extra-index-urls https://azuremlsdktestpypi.azureedge.net/CLI-SDK-Runners-Validation/13405526 --yes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the availability of `az ml module` commands\n",
    "!az ml module -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install azureml-sdk with Pipeline, Module\n",
    "# Important! After install succeed, need to restart kernel\n",
    "\n",
    "%config IPCompleter.greedy=True \n",
    "!pip install azureml-pipeline-wrapper==0.1.0.13487048 --extra-index-url https://azuremlsdktestpypi.azureedge.net/CLI-SDK-Runners-Validation/13487048 --user --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register azureml module\n",
    "\n",
    "You can manage AML module through [azure-cli-ml](https://aka.ms/moduledoc) or [ml.azure.com](https://ml.azure.com/). <br>\n",
    "\n",
    "Module could be registered from:\n",
    "- local path\n",
    "- public Github url\n",
    "- Azure DevOps build artifacts\n",
    "\n",
    "Azureml module support multiple module type:\n",
    "- Basic python module\n",
    "- Mpi module\n",
    "- Parallel run module\n",
    "- Hdi module (pending on backend support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to configure your ws information here\n",
    "\n",
    "subscription_id = '74eccef0-4b8d-4f83-b5f9-fa100d155b22'\n",
    "workspace_name = 'lisal-amlservice'\n",
    "resource_group = 'lisal-dev'\n",
    "\n",
    "# Specify available aml compute in workspace\n",
    "pipeline_compute = \"always-on-ds2v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your aml workspace \n",
    "\n",
    "!az login \n",
    "!az account set -s $subscription_id \n",
    "!az ml folder attach -w $workspace_name -g $resource_group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register azureml modules from github url\n",
    "\n",
    "!az ml module register --spec-file=https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/mpi_train.yaml \n",
    "!az ml module register --spec-file=https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/score.yaml \n",
    "!az ml module register --spec-file=https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/eval.yaml \n",
    "!az ml module register --spec-file=https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/compare2.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list available custom module in aml workspace\n",
    "!az ml module list -o table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline\n",
    "You can build pipeline through SDK experience, or drag-n-drop way through [Designer](https://ml.azure.com/visualinterface?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/kubeflow-demo/workspaces/kubeflow_ws_1&flight=cm,nml,newGraphDetail,newGraphAuthoring,all&tid=72f988bf-86f1-41af-91ab-2d7cd011db47) in workspace portal\n",
    "\n",
    "The new SDK:\n",
    "* Symplified the syntax to provide consistent experience with drag-n-drop\n",
    "* Support intellisense and docstring, free you to work with dict all the time\n",
    "* Support creating a pipeline with unpublished module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Run, Dataset\n",
    "from azureml.pipeline.wrapper import Pipeline, Module, dsl\n",
    "\n",
    "ws = Workspace.get(name=workspace_name, subscription_id=subscription_id, resource_group=resource_group)\n",
    "\n",
    "# get modules\n",
    "train_module_func = Module.load(ws, namespace='microsoft.com/aml/samples', name='MPI Train')\n",
    "score_module_func = Module.load(ws, namespace='microsoft.com/aml/samples', name='Score')\n",
    "eval_module_func = Module.load(ws, namespace='microsoft.com/aml/samples', name='Evaluate')\n",
    "compare_module_func = Module.load(ws, namespace='microsoft.com/aml/samples', name='Compare 2 Models')\n",
    "\n",
    "# if you have unpublished module in local or github, below function allow user to test as anounymous module\n",
    "# compare_module_func = Module.load_from_yaml(ws, yaml_file='./CompareModdels/compare2.yaml')\n",
    "# compare_module_func = Module.load_from_yaml(ws, yaml_file='https://github.com/lisagreenview/hello-aml-modules/blob/master/train-score-eval/compare2.yaml')\n",
    "\n",
    "# get dataset\n",
    "training_data_name = 'aml_module_training_data'\n",
    "test_data_name = 'aml_module_test_data'\n",
    "\n",
    "if training_data_name not in ws.datasets:\n",
    "    print('Registering a training dataset for sample pipeline ...')\n",
    "    training_dataset = Dataset.File.from_files(path=['https://dprepdata.blob.core.windows.net/demo/Titanic.csv'])\n",
    "    training_dataset.register(workspace   = ws, \n",
    "                              name        = training_data_name, \n",
    "                              description = 'Training data (just for illustrative purpose)')\n",
    "    print('Registerd')\n",
    "else:\n",
    "    ws.datasets[training_data_name)\n",
    "    print('Training dataset found in workspace')\n",
    "\n",
    "if test_data_name not in ws.datasets:\n",
    "    print('Registering a test dataset for sample pipeline ...')\n",
    "    test_dataset = Dataset.File.from_files(path=['https://dprepdata.blob.core.windows.net/demo/Titanic.csv'])\n",
    "    test_dataset.register(workspace   = ws, \n",
    "                          name        = test_data_name, \n",
    "                          description = 'Test data (just for illustrative purpose)')\n",
    "    print('Registered')\n",
    "else:\n",
    "    test_dataset = ws.datasets[test_data_name]    \n",
    "    print('Test dataset found in workspace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(train_module_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_module_func(training_data=train_data, max_epochs=5, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a sub pipeline\n",
    "@dsl.pipeline(name = 'A sub pipeline including train/score/eval', \n",
    "              description = 'train model and evaluate model perf')\n",
    "def training_pipeline(input_data, learning_rate):\n",
    "    train = train_module_func(\n",
    "        training_data=input_data, \n",
    "        max_epochs=5, \n",
    "        learning_rate=learning_rate)\n",
    "   \n",
    "    train.runsettings.configure(process_count_per_node = 2, node_count = 2)\n",
    "\n",
    "    score = score_module_func(\n",
    "        model_input=train.outputs.model_output, \n",
    "        test_data=test_data)\n",
    "\n",
    "    eval = eval_module_func(scoring_result=score.outputs.score_output)\n",
    "    \n",
    "    return {'eval_output': eval.outputs.eval_output, 'model_output': train.outputs.model_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline with sub pipeline\n",
    "@dsl.pipeline(name = 'A dummy pipeline that trains multiple models and output the best one', \n",
    "              description = 'select best model trained with different learning rate',\n",
    "              default_compute_target = pipeline_compute)\n",
    "def dummy_automl_pipeline():\n",
    "    train_and_evalute_model1 = training_pipeline(train_data, 0.01)\n",
    "    train_and_evalute_model2 = training_pipeline(train_data, 0.02)\n",
    "    \n",
    "    compare = compare_module_func(\n",
    "        model1=train_and_evalute_model1.outputs.model_output, \n",
    "        eval_result1=train_and_evalute_model1.outputs.eval_output,\n",
    "        model2=train_and_evalute_model2.outputs.model_output,\n",
    "        eval_result2=train_and_evalute_model2.outputs.eval_output\n",
    "    )\n",
    "\n",
    "    return {**compare.outputs}\n",
    "\n",
    "# create a pipeline\n",
    "pipeline = dummy_automl_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# validate pipeline and visualize the graph\n",
    "pipeline.validate(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a draft\n",
    "pipeline.save_as_pipeline_draft(    \n",
    "    ws,\n",
    "    experiment_name = 'pipeline-with-azureml-module'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit a pipeline run\n",
    "run = pipeline.submit_run(\n",
    "    ws,\n",
    "    experiment_name = 'pipeline-with-azureml-module'\n",
    ")\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}